{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1b6b7d",
   "metadata": {},
   "source": [
    "# Forecasting Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aecec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Viz Packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Modeling Packages\n",
    "## Modeling Prep\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold, \\\n",
    "GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "## SKLearn Data Prep Modules\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, \\\n",
    "PolynomialFeatures, PowerTransformer, Normalizer, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## SKLearn Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## SKLearn Pipeline and Transformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## SKLearn Model Optimization\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "\n",
    "## SKLearn Metrics\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE\n",
    "\n",
    "## Statsmodel Time Series modules\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import SARIMAX, AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "## Holidays package\n",
    "from datetime import date\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735f3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Config\n",
    "## Suppress Python Warnings (Future, Deprecation)\n",
    "warnings.filterwarnings(\"ignore\", category= FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "## Suppress Pandas Warnings (SettingWithCopy)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "## Pandas Display Config\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "\n",
    "## Display SKLearn estimators as diagrams\n",
    "from sklearn import set_config\n",
    "set_config(display= 'diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b0e5c",
   "metadata": {},
   "source": [
    "## Read in and Inspect the provided datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a19a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the provided datasets\n",
    "stores_df = pd.read_csv('data/stores.csv')\n",
    "features_df = pd.read_csv('data/features.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "train_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f7f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect stores df\n",
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fab175",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df.info() # no missing values, convert type to nominal or ordinal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a4c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09cc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the features data\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad48c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.info() # Missing markdown values as expected, some nulls for CPI and unemployment as well\n",
    "# Need to convert 'Date' to datetime and 'IsHoliday' to numerical bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be8226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ff9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the provided datasets\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6577569",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info() # Has the most values - merge stores and features onto this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89df122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the test data\n",
    "test_df.head() # will need to also merge the stores and features datasets to our test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5bc2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info() # roughly 80/20 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af35eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "train_df = train_df.merge(features_df, how='left').merge(stores_df, how='left')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8cc831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to group similar features \n",
    "cols = list(train_df.columns.values)\n",
    "cols # move 'Type' and 'Size' to after 'Dept', 'CPI' and 'Unemployment' after 'Fuel_Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de5a74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite df with new column ordering\n",
    "train_df = train_df[['Store','Dept','Type','Size','Date','Weekly_Sales','IsHoliday','Temperature',\n",
    "                         'Fuel_Price','CPI','Unemployment','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n",
    "                         'MarkDown5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0f4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets for testing set to mirror training set\n",
    "test_df = test_df.merge(features_df, how='left').merge(stores_df, how='left')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c21ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to hold predicted weekly sales values \n",
    "test_df['Weekly_Sales'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4228111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns to mirror transformation to training df\n",
    "test_df = test_df[['Store','Dept','Type','Size','Date','Weekly_Sales','IsHoliday','Temperature',\n",
    "                         'Fuel_Price','CPI','Unemployment','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n",
    "                         'MarkDown5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03909d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1a5d2",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48eefb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nulls and dytpes again\n",
    "train_df.info() # no nulls in CPI and Unemployment now, will need to see what's going there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "368d07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['CPI'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37b541fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Unemployment'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4c176a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum() # no more missing values - different reporting windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa8a57c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize feature distributions excl markdown and sales cols with scatter plots\n",
    "cols_to_scatter = ['Store','Dept','Type','Size','Date','IsHoliday','Temperature',\n",
    "                   'Fuel_Price','CPI','Unemployment']\n",
    "for col in cols_to_scatter:\n",
    "    plt.figure()\n",
    "    plt.scatter(train_df[col], train_df['Weekly_Sales'])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Weekly_Sales')\n",
    "    plt.figure(figsize=(6,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1015162",
   "metadata": {},
   "source": [
    "While some type 'B' and midsize stores have sales numbers bigger than some type 'A' and larger stores, we'll handle type ordinally\n",
    "- big drop off when store type is 'C'\n",
    "\n",
    "Two huge sales bumps in the date plot\n",
    "- guessing its thanksgiving/black friday and christmas, but we'll want to drill down on that later \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a0840eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation of numerical features\n",
    "plt.figure(figsize=(20,10))\n",
    "cor = train_df.corr()\n",
    "sns.heatmap(cor, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f694e20",
   "metadata": {},
   "source": [
    "- nothing really jumps out as being highly correlated\n",
    "- unexpectedly low correlation for many features such as markdowns and external factors such as CPI, gas prices, and the unemployment rate\n",
    "- could be a case where the best predictor of future values is truly past values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33358bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract years, months, weeks from the date and weekly sales into new cols for testing and training dfs\n",
    "# allows us to group sales by diffrent windows and plot so we can look for trends\n",
    "# Also necessary for running models later on\n",
    "# Convert date col to datetime object for training and test sets\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "\n",
    "# Extract Years, Months, and Weeks from date col in both sets\n",
    "train_df['Year'] = train_df['Date'].dt.year\n",
    "train_df['Month'] = train_df['Date'].dt.month\n",
    "train_df['Week'] = train_df['Date'].dt.week\n",
    "\n",
    "test_df['Year'] = test_df['Date'].dt.year\n",
    "test_df['Month'] = test_df['Date'].dt.month\n",
    "test_df['Week'] = test_df['Date'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43b2e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate average sales by year by week to indentify trends in weekly sales \n",
    "weekly_2010 = train_df.loc[train_df['Year'] == 2010].groupby('Week')['Weekly_Sales'].mean().reset_index()\n",
    "weekly_2011 = train_df.loc[train_df['Year'] == 2011].groupby('Week')['Weekly_Sales'].mean().reset_index()\n",
    "weekly_2012 = train_df.loc[train_df['Year'] == 2012].groupby('Week')['Weekly_Sales'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64f12dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weekly sales \n",
    "sns.lineplot(weekly_2010)\n",
    "# plt.plot(weekly_2011)\n",
    "# plt.plot(weekly_2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a557d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02797bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82194bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d783b576",
   "metadata": {},
   "source": [
    "## Save this for the propeht modeling which takes a holiday argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5e521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afca9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c3079c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of US holidays from the holidays python package for the applicable years (2010,2011,2012)\n",
    "for date, name in sorted(holidays.US(years=[2010,2011,2012]).items()):\n",
    "    print(date, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351aa233",
   "metadata": {},
   "source": [
    "Thanksgiving and Black Friday (tgiving +1) always fall in november\n",
    "- could categorize month 11 as 'thanksgiving' or assign thanksgiving and black friday to the appropriate week number\n",
    "\n",
    "New Years is technically always in a new week/month/year, however case to be made for grouping with xmas\n",
    "- could categorize month 12 as xmas & new years or assign to the appropriate week number\n",
    "- more inclined to encode on monthly basis as trend has been for an ever longer holiday shopping window\n",
    "\n",
    "Holidays to look at not included in the standard list are:\n",
    "- Super bowl weekend (\n",
    "- Valentine's day \n",
    "- Easter\n",
    "\n",
    "Holidays not associated with high levels of consumerism to remove\n",
    "- Martin Luther King Jr. Day\n",
    "- Washington's Birthday\n",
    "- Veterans Day\n",
    "- Columbus Day\n",
    "- 'Observed' dates\n",
    "\n",
    "Other Notes:\n",
    "- Labor day is not in the test set so we don't need to predict for that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36abd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal-ball",
   "language": "python",
   "name": "crystal-ball"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
